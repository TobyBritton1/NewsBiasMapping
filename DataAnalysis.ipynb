{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Data Analysis<h1><center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Toby\n",
      "[nltk_data]     Britton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Metrics import getSentiment, getFactBased\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File\n",
      "File Loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading File\")\n",
    "file = open(\"rust-articles-backup.json\", encoding=\"utf8\")\n",
    "articles = pd.DataFrame.from_dict(json.load(file))\n",
    "print(\"File Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     32619\n",
      "dailymail,news                                       15066\n",
      "sport,football                                        6422\n",
      "news,uk news                                          3814\n",
      "dailymail,news,coronavirus                            3429\n",
      "                                                     ...  \n",
      "dailymail,sciencetech,israel,france                      1\n",
      "dailymail,sciencetech,texas,nasa                         1\n",
      "dailymail,news,bbc,boris johnson,nhs                     1\n",
      "dailymail,news,london,christmas,liberal democrats        1\n",
      "dailymail,news,leonardo dicaprio,coronavirus             1\n",
      "Name: categories, Length: 12742, dtype: int64\n",
      "['url', 'publisher', 'headline', 'twitterHeadline', 'description', 'categories', 'body', 'images', 'thumbnail', 'videos', 'datePublished', 'dateUpdated', 'dateParsed']\n"
     ]
    }
   ],
   "source": [
    "# print(articles['publisher'].value_counts())\n",
    "print(articles['categories'].value_counts())\n",
    "print(list(articles.columns))\n",
    "# print(articles['body'][articles['categories'].str.contains('leonardo dicaprio')].reset_index(drop=True)[1])\n",
    "# print(articles['body'][articles['categories'].str.contains('opinion')].reset_index(drop=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.038, 'neu': 0.886, 'pos': 0.077, 'compound': 0.9554}\n",
      "\n",
      "{'neg': 0.088, 'neu': 0.842, 'pos': 0.07, 'compound': -0.8484}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "for i in range(a*2,a*2+2):\n",
    "    sentiment = getSentiment(articles.at[i,'body'])\n",
    "    #print(articles.at[i,'body'])\n",
    "    print(sentiment)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion: 1840 -0.73251\n",
      "Fact: 159385 -0.64425\n",
      "All: 161225 -0.64526\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "opp = []\n",
    "o = articles[articles['categories'].str.contains('opinion')].reset_index(drop=True)\n",
    "for i in range(len(o)):\n",
    "    factBased,_,_ = getFactBased(o.at[i,'body'])\n",
    "    # print(ob.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    opp.append(factBased)\n",
    "print('Opinion:',count, round(total/count,5))\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "fac = []\n",
    "f = articles[~articles['categories'].str.contains('opinion')].reset_index(drop=True)\n",
    "for i in range(len(f)):\n",
    "    factBased,_,_ = getFactBased(f.at[i,'body'])\n",
    "    # print(fb.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    fac.append(factBased)\n",
    "print('Fact:',count, round(total/count,5))\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "all = []\n",
    "for i in range(len(articles)):\n",
    "    factBased,_,_ = getFactBased(articles.at[i,'body'])\n",
    "    # print(fb.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    all.append(factBased)\n",
    "print('All:',count, round(total/count,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.888889"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "training_x = pd.DataFrame([1,10,1,10])\n",
    "training_y = pd.DataFrame([1,0,1,0])\n",
    "testing_x = pd.DataFrame([2])\n",
    "\n",
    "model = LinearRegression().fit(training_x.to_numpy(), training_y.to_numpy().ravel())\n",
    "result = pd.DataFrame(model.predict(testing_x.to_numpy()))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7d4014459f57a0efa793e05d0e4bb89c114d3769303d98e183726ce8d7327a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
