{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Data Analysis<h1><center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\britt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Metrics import getSentiment, getFactBased, getSensationalized\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading File\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mrust-articles-backup.json\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m articles \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mfrom_dict(json\u001b[39m.\u001b[39;49mload(file))\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFile Loaded\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\britt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:1651\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1646\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m \u001b[39m# IO methods (to / from other formats)\u001b[39;00m\n\u001b[1;32m-> 1651\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1652\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_dict\u001b[39m(\n\u001b[0;32m   1653\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   1654\u001b[0m     data: \u001b[39mdict\u001b[39m,\n\u001b[0;32m   1655\u001b[0m     orient: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1656\u001b[0m     dtype: Dtype \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1657\u001b[0m     columns: Axes \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1658\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   1659\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[39m    Construct DataFrame from dict of array-like or dicts.\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m \u001b[39m       c   2  4\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1741\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading File\")\n",
    "file = open(\"rust-articles-backup.json\", encoding=\"utf8\")\n",
    "articles = pd.DataFrame.from_dict(json.load(file))\n",
    "print(\"File Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'publisher', 'headline', 'twitterHeadline', 'description', 'categories', 'body', 'images', 'thumbnail', 'videos', 'datePublished', 'dateUpdated', 'dateParsed']\n"
     ]
    }
   ],
   "source": [
    "# print(articles['publisher'].value_counts())\n",
    "# print(articles['categories'].value_counts())\n",
    "print(list(articles.columns))\n",
    "# print(articles['body'][articles['categories'].str.contains('leonardo dicaprio')].reset_index(drop=True)[1])\n",
    "# print(articles['body'][articles['categories'].str.contains('opinion')].reset_index(drop=True)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Sentiment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.038, 'neu': 0.886, 'pos': 0.077, 'compound': 0.9554}\n",
      "\n",
      "{'neg': 0.088, 'neu': 0.842, 'pos': 0.07, 'compound': -0.8484}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "for i in range(a*2,a*2+2):\n",
    "    sentiment = getSentiment(articles.at[i,'body'])\n",
    "    #print(articles.at[i,'body'])\n",
    "    print(sentiment)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Factbased Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion: 1840 -0.73251\n",
      "Fact: 159385 -0.64425\n",
      "All: 161225 -0.64526\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "opp = []\n",
    "o = articles[articles['categories'].str.contains('opinion')].reset_index(drop=True)\n",
    "for i in range(len(o)):\n",
    "    factBased,_,_ = getFactBased(o.at[i,'body'])\n",
    "    # print(ob.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    opp.append(factBased)\n",
    "print('Opinion:',count, round(total/count,5))\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "fac = []\n",
    "f = articles[~articles['categories'].str.contains('opinion')].reset_index(drop=True)\n",
    "for i in range(len(f)):\n",
    "    factBased,_,_ = getFactBased(f.at[i,'body'])\n",
    "    # print(fb.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    fac.append(factBased)\n",
    "print('Fact:',count, round(total/count,5))\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "all = []\n",
    "for i in range(len(articles)):\n",
    "    factBased,_,_ = getFactBased(articles.at[i,'body'])\n",
    "    # print(fb.at[i,'body'])\n",
    "    # print(factBased)\n",
    "    count += 1\n",
    "    total += factBased\n",
    "    all.append(factBased)\n",
    "print('All:',count, round(total/count,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.888889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "training_x = pd.DataFrame([1,10,1,10])\n",
    "training_y = pd.DataFrame([1,0,1,0])\n",
    "testing_x = pd.DataFrame([2])\n",
    "\n",
    "model = LinearRegression().fit(training_x.to_numpy(), training_y.to_numpy().ravel())\n",
    "result = pd.DataFrame(model.predict(testing_x.to_numpy()))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(getSensationalized('stunningly terrifying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello hello'\n",
    "a.count('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7d4014459f57a0efa793e05d0e4bb89c114d3769303d98e183726ce8d7327a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
